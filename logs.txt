 docker-compose up --build

WARN[0000] /Users/ayoub/work/Nexus/ex00/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion 
[+] Building 1.9s (12/12) FINISHED                                                                                                                                                  
 => [internal] load local bake definitions                                                                                                                                     0.0s
 => => reading from stdin 365B                                                                                                                                                 0.0s
 => [internal] load build definition from Dockerfile                                                                                                                           0.0s
 => => transferring dockerfile: 447B                                                                                                                                           0.0s
 => [internal] load metadata for docker.io/library/python:3.13.9-slim                                                                                                          1.7s
 => [internal] load .dockerignore                                                                                                                                              0.0s
 => => transferring context: 2B                                                                                                                                                0.0s
 => [1/5] FROM docker.io/library/python:3.13.9-slim@sha256:326df678c20c78d465db501563f3492d17c42a4afe33a1f2bf5406a1d56b0e86                                                    0.0s
 => => resolve docker.io/library/python:3.13.9-slim@sha256:326df678c20c78d465db501563f3492d17c42a4afe33a1f2bf5406a1d56b0e86                                                    0.0s
 => [internal] load build context                                                                                                                                              0.0s
 => => transferring context: 4.10kB                                                                                                                                            0.0s
 => CACHED [2/5] WORKDIR /app                                                                                                                                                  0.0s
 => CACHED [3/5] COPY requirements.txt .                                                                                                                                       0.0s
 => CACHED [4/5] RUN pip install --no-cache-dir -r requirements.txt                                                                                                            0.0s
 => [5/5] COPY generator.py .                                                                                                                                                  0.0s
 => exporting to image                                                                                                                                                         0.0s
 => => exporting layers                                                                                                                                                        0.0s
 => => exporting manifest sha256:fb72c970812edcd694f75eacd1b14e32c55e1614cb69c63129a5aca3ed53d237                                                                              0.0s
 => => exporting config sha256:64b98bc75594950859d4a340b80f3366393b6afa75d99fd256d98da22163cd1a                                                                                0.0s
 => => exporting attestation manifest sha256:58994813f5029009289485806c2b13a99b2453073a11b03a9987547318dc1d8a                                                                  0.0s
 => => exporting manifest list sha256:b424f100cead095fb6aa1fc4a3bed4ef64abdd7869251edba392842bf65cd74b                                                                         0.0s
 => => naming to docker.io/library/ex00-generator:latest                                                                                                                       0.0s
 => => unpacking to docker.io/library/ex00-generator:latest                                                                                                                    0.0s
 => resolving provenance for metadata file                                                                                                                                     0.0s
[+] Running 8/8
 ✔ generator                                                                                                                                                Bui...             0.0s 
 ✔ Network ex00_default                                                                                                                                     Created            0.0s 
 ✔ Container minio                                                                                                                                          Created            0.0s 
 ✔ Container zookeeper                                                                                                                                      Created            0.0s 
 ! zookeeper The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested                    0.0s 
 ✔ Container kafka                                                                                                                                          Created            0.0s 
 ! kafka The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested                        0.0s 
 ✔ Container generator                                                                                                                                      Created            0.0s 
Attaching to generator, kafka, minio, zookeeper
zookeeper  | ===> User
zookeeper  | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
zookeeper  | ===> Configuring ...
kafka      | ===> User
kafka      | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
kafka      | ===> Configuring ...
minio      | INFO: Formatting 1st pool, 1 set(s), 1 drives per set.
minio      | INFO: WARNING: Host local has more than 0 drives of set. A host failure will result in data becoming unavailable.
minio      | MinIO Object Storage Server
minio      | Copyright: 2015-2025 MinIO, Inc.
minio      | License: GNU AGPLv3 - https://www.gnu.org/licenses/agpl-3.0.html
minio      | Version: RELEASE.2025-09-07T16-13-09Z (go1.24.6 linux/arm64)
minio      | 
minio      | API: http://172.18.0.3:9000  http://127.0.0.1:9000 
minio      | WebUI: http://172.18.0.3:9001 http://127.0.0.1:9001  
minio      | 
minio      | Docs: https://docs.min.io
minio      | WARN: Detected default credentials 'minioadmin:minioadmin', we recommend that you change these values with 'MINIO_ROOT_USER' and 'MINIO_ROOT_PASSWORD' environment variables
zookeeper  | ===> Running preflight checks ... 
zookeeper  | ===> Check if /var/lib/zookeeper/data is writable ...
zookeeper  | ===> Check if /var/lib/zookeeper/log is writable ...
zookeeper  | ===> Launching ... 
kafka      | ===> Running preflight checks ... 
zookeeper  | ===> Launching zookeeper ... 
kafka      | ===> Check if /var/lib/kafka/data is writable ...
kafka      | ===> Check if Zookeeper is healthy ...
kafka      | SLF4J: Class path contains multiple SLF4J bindings.
kafka      | SLF4J: Found binding in [jar:file:/usr/share/java/cp-base-new/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
kafka      | SLF4J: Found binding in [jar:file:/usr/share/java/cp-base-new/slf4j-simple-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
kafka      | SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
kafka      | SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
kafka      | log4j:WARN No appenders could be found for logger (io.confluent.admin.utils.cli.ZookeeperReadyCommand).
kafka      | log4j:WARN Please initialize the log4j system properly.
kafka      | log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
zookeeper  | [2025-12-08 00:47:32,549] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,559] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,559] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,559] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,559] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,560] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
zookeeper  | [2025-12-08 00:47:32,560] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
zookeeper  | [2025-12-08 00:47:32,560] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
zookeeper  | [2025-12-08 00:47:32,560] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
zookeeper  | [2025-12-08 00:47:32,563] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
zookeeper  | [2025-12-08 00:47:32,573] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,574] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,574] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,574] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,574] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper  | [2025-12-08 00:47:32,574] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
zookeeper  | [2025-12-08 00:47:32,591] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@52102734 (org.apache.zookeeper.server.ServerMetrics)
zookeeper  | [2025-12-08 00:47:32,593] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
zookeeper  | [2025-12-08 00:47:32,602] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,602] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,602] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,602] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,602] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,602] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,602] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,602] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,602] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,602] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:host.name=e7ff5a50437b (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:java.version=11.0.13 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:java.class.path=/usr/bin/../share/java/kafka/netty-transport-4.1.68.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/kafka-clients-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.68.Final.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.68.Final.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.6.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.68.Final.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.30.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/connect-runtime-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.12.3.jar:/usr/bin/../share/java/kafka/jackson-core-2.12.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.12.3.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/connect-api-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.3.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.12.3.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.12.3.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.30.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.12.3.jar:/usr/bin/../share/java/kafka/jline-3.12.1.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.3.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.1.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.68.Final.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/trogdor-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.68.Final.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/lz4-java-1.7.1.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/scala-library-2.13.6.jar:/usr/bin/../share/java/kafka/connect-json-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.1.jar:/usr/bin/../share/java/kafka/kafka-tools-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.3.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/connect-transforms-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/kafka-shell-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.12.3.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.0.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.68.Final.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.4.4.jar:/usr/bin/../share/java/kafka/confluent-log4j-1.2.17-cp2.jar:/usr/bin/../share/java/kafka/netty-common-4.1.68.Final.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.1.jar:/usr/bin/../share/java/kafka/rocksdbjni-6.19.3.jar:/usr/bin/../share/java/kafka/jackson-databind-2.12.3.jar:/usr/bin/../share/java/kafka/kafka-streams-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/connect-mirror-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.12.3.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.2.1.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.0-2.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:os.version=6.10.14-linuxkit (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:user.name=appuser (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:user.home=/home/appuser (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:user.dir=/home/appuser (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:os.memory.free=492MB (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,603] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,604] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,604] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,604] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,604] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,604] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
zookeeper  | [2025-12-08 00:47:32,605] INFO minSessionTimeout set to 4000 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,605] INFO maxSessionTimeout set to 40000 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,606] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
zookeeper  | [2025-12-08 00:47:32,606] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
zookeeper  | [2025-12-08 00:47:32,606] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper  | [2025-12-08 00:47:32,607] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper  | [2025-12-08 00:47:32,607] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper  | [2025-12-08 00:47:32,607] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper  | [2025-12-08 00:47:32,607] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper  | [2025-12-08 00:47:32,607] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper  | [2025-12-08 00:47:32,609] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,609] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,609] INFO Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 clientPortListenBacklog -1 datadir /var/lib/zookeeper/log/version-2 snapdir /var/lib/zookeeper/data/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,628] INFO Logging initialized @897ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
zookeeper  | [2025-12-08 00:47:32,759] WARN o.e.j.s.ServletContextHandler@2584b82d{/,null,STOPPED} contextPath ends with /* (org.eclipse.jetty.server.handler.ContextHandler)
zookeeper  | [2025-12-08 00:47:32,759] WARN Empty contextPath (org.eclipse.jetty.server.handler.ContextHandler)
zookeeper  | [2025-12-08 00:47:32,788] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS (org.eclipse.jetty.server.Server)
zookeeper  | [2025-12-08 00:47:32,820] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
zookeeper  | [2025-12-08 00:47:32,820] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
zookeeper  | [2025-12-08 00:47:32,822] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
zookeeper  | [2025-12-08 00:47:32,826] WARN ServletContext@o.e.j.s.ServletContextHandler@2584b82d{/,null,STARTING} has uncovered http methods for path: /* (org.eclipse.jetty.security.SecurityHandler)
zookeeper  | [2025-12-08 00:47:32,832] INFO Started o.e.j.s.ServletContextHandler@2584b82d{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
zookeeper  | [2025-12-08 00:47:32,849] INFO Started ServerConnector@247310d0{HTTP/1.1, (http/1.1)}{0.0.0.0:8080} (org.eclipse.jetty.server.AbstractConnector)
zookeeper  | [2025-12-08 00:47:32,849] INFO Started @1118ms (org.eclipse.jetty.server.Server)
zookeeper  | [2025-12-08 00:47:32,849] INFO Started AdminServer on address 0.0.0.0, port 8080 and command URL /commands (org.apache.zookeeper.server.admin.JettyAdminServer)
zookeeper  | [2025-12-08 00:47:32,852] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
zookeeper  | [2025-12-08 00:47:32,853] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
zookeeper  | [2025-12-08 00:47:32,853] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 20 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
zookeeper  | [2025-12-08 00:47:32,854] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
zookeeper  | [2025-12-08 00:47:32,863] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
zookeeper  | [2025-12-08 00:47:32,864] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
zookeeper  | [2025-12-08 00:47:32,864] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
zookeeper  | [2025-12-08 00:47:32,864] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
zookeeper  | [2025-12-08 00:47:32,871] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
zookeeper  | [2025-12-08 00:47:32,871] INFO Snapshotting: 0x0 to /var/lib/zookeeper/data/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
zookeeper  | [2025-12-08 00:47:32,872] INFO Snapshot loaded in 8 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
zookeeper  | [2025-12-08 00:47:32,872] INFO Snapshotting: 0x0 to /var/lib/zookeeper/data/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
zookeeper  | [2025-12-08 00:47:32,873] INFO Snapshot taken in 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper  | [2025-12-08 00:47:32,876] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
zookeeper  | [2025-12-08 00:47:32,876] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
zookeeper  | [2025-12-08 00:47:32,895] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
zookeeper  | [2025-12-08 00:47:32,896] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
zookeeper  | [2025-12-08 00:47:33,742] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
kafka      | ===> Launching ... 
kafka      | ===> Launching kafka ... 
kafka      | [2025-12-08 00:47:35,105] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
kafka      | [2025-12-08 00:47:35,376] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
kafka      | [2025-12-08 00:47:35,441] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafka      | [2025-12-08 00:47:35,444] INFO starting (kafka.server.KafkaServer)
kafka      | [2025-12-08 00:47:35,444] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
kafka      | [2025-12-08 00:47:35,452] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:host.name=8ea92a75fcfd (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:java.version=11.0.13 (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/netty-transport-4.1.68.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/kafka-clients-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.68.Final.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.68.Final.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.6.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.68.Final.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.30.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/connect-runtime-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.12.3.jar:/usr/bin/../share/java/kafka/jackson-core-2.12.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.12.3.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/connect-api-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.3.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.12.3.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.12.3.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.30.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.12.3.jar:/usr/bin/../share/java/kafka/jline-3.12.1.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.3.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.1.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.68.Final.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/trogdor-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.68.Final.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/lz4-java-1.7.1.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/scala-library-2.13.6.jar:/usr/bin/../share/java/kafka/connect-json-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.1.jar:/usr/bin/../share/java/kafka/kafka-tools-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.3.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/connect-transforms-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/kafka-shell-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.12.3.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.0.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.68.Final.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.4.4.jar:/usr/bin/../share/java/kafka/confluent-log4j-1.2.17-cp2.jar:/usr/bin/../share/java/kafka/netty-common-4.1.68.Final.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.1.jar:/usr/bin/../share/java/kafka/rocksdbjni-6.19.3.jar:/usr/bin/../share/java/kafka/jackson-databind-2.12.3.jar:/usr/bin/../share/java/kafka/kafka-streams-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.43.v20210629.jar:/usr/bin/../share/java/kafka/connect-mirror-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.12.3.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.0.1-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.2.1.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.0-2.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:os.version=6.10.14-linuxkit (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,455] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,456] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@628c4ac0 (org.apache.zookeeper.ZooKeeper)
kafka      | [2025-12-08 00:47:35,459] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
kafka      | [2025-12-08 00:47:35,462] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
kafka      | [2025-12-08 00:47:35,466] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
kafka      | [2025-12-08 00:47:35,477] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
kafka      | [2025-12-08 00:47:35,477] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka      | [2025-12-08 00:47:35,483] INFO Socket connection established, initiating session, client: /172.18.0.4:54122, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
kafka      | [2025-12-08 00:47:35,492] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x1000017db8d0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
kafka      | [2025-12-08 00:47:35,495] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
kafka      | [2025-12-08 00:47:35,568] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
kafka      | [2025-12-08 00:47:35,577] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
kafka      | [2025-12-08 00:47:35,577] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
kafka      | [2025-12-08 00:47:35,675] INFO Cluster ID = pWTQW8X8QMG_8NHg9W6CEQ (kafka.server.KafkaServer)
kafka      | [2025-12-08 00:47:35,679] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
kafka      | [2025-12-08 00:47:35,706] INFO KafkaConfig values: 
kafka      |    advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
kafka      |    alter.config.policy.class.name = null
kafka      |    alter.log.dirs.replication.quota.window.num = 11
kafka      |    alter.log.dirs.replication.quota.window.size.seconds = 1
kafka      |    authorizer.class.name = 
kafka      |    auto.create.topics.enable = true
kafka      |    auto.leader.rebalance.enable = true
kafka      |    background.threads = 10
kafka      |    broker.heartbeat.interval.ms = 2000
kafka      |    broker.id = 1
kafka      |    broker.id.generation.enable = true
kafka      |    broker.rack = null
kafka      |    broker.session.timeout.ms = 9000
kafka      |    client.quota.callback.class = null
kafka      |    compression.type = producer
kafka      |    connection.failed.authentication.delay.ms = 100
kafka      |    connections.max.idle.ms = 600000
kafka      |    connections.max.reauth.ms = 0
kafka      |    control.plane.listener.name = null
kafka      |    controlled.shutdown.enable = true
kafka      |    controlled.shutdown.max.retries = 3
kafka      |    controlled.shutdown.retry.backoff.ms = 5000
kafka      |    controller.listener.names = null
kafka      |    controller.quorum.append.linger.ms = 25
kafka      |    controller.quorum.election.backoff.max.ms = 1000
kafka      |    controller.quorum.election.timeout.ms = 1000
kafka      |    controller.quorum.fetch.timeout.ms = 2000
kafka      |    controller.quorum.request.timeout.ms = 2000
kafka      |    controller.quorum.retry.backoff.ms = 20
kafka      |    controller.quorum.voters = []
kafka      |    controller.quota.window.num = 11
kafka      |    controller.quota.window.size.seconds = 1
kafka      |    controller.socket.timeout.ms = 30000
kafka      |    create.topic.policy.class.name = null
kafka      |    default.replication.factor = 1
kafka      |    delegation.token.expiry.check.interval.ms = 3600000
kafka      |    delegation.token.expiry.time.ms = 86400000
kafka      |    delegation.token.master.key = null
kafka      |    delegation.token.max.lifetime.ms = 604800000
kafka      |    delegation.token.secret.key = null
kafka      |    delete.records.purgatory.purge.interval.requests = 1
kafka      |    delete.topic.enable = true
kafka      |    fetch.max.bytes = 57671680
kafka      |    fetch.purgatory.purge.interval.requests = 1000
kafka      |    group.initial.rebalance.delay.ms = 3000
kafka      |    group.max.session.timeout.ms = 1800000
kafka      |    group.max.size = 2147483647
kafka      |    group.min.session.timeout.ms = 6000
kafka      |    initial.broker.registration.timeout.ms = 60000
kafka      |    inter.broker.listener.name = null
kafka      |    inter.broker.protocol.version = 3.0-IV1
kafka      |    kafka.metrics.polling.interval.secs = 10
kafka      |    kafka.metrics.reporters = []
kafka      |    leader.imbalance.check.interval.seconds = 300
kafka      |    leader.imbalance.per.broker.percentage = 10
kafka      |    listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
kafka      |    listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
kafka      |    log.cleaner.backoff.ms = 15000
kafka      |    log.cleaner.dedupe.buffer.size = 134217728
kafka      |    log.cleaner.delete.retention.ms = 86400000
kafka      |    log.cleaner.enable = true
kafka      |    log.cleaner.io.buffer.load.factor = 0.9
kafka      |    log.cleaner.io.buffer.size = 524288
kafka      |    log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka      |    log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka      |    log.cleaner.min.cleanable.ratio = 0.5
kafka      |    log.cleaner.min.compaction.lag.ms = 0
kafka      |    log.cleaner.threads = 1
kafka      |    log.cleanup.policy = [delete]
kafka      |    log.dir = /tmp/kafka-logs
kafka      |    log.dirs = /var/lib/kafka/data
kafka      |    log.flush.interval.messages = 9223372036854775807
kafka      |    log.flush.interval.ms = null
kafka      |    log.flush.offset.checkpoint.interval.ms = 60000
kafka      |    log.flush.scheduler.interval.ms = 9223372036854775807
kafka      |    log.flush.start.offset.checkpoint.interval.ms = 60000
kafka      |    log.index.interval.bytes = 4096
kafka      |    log.index.size.max.bytes = 10485760
kafka      |    log.message.downconversion.enable = true
kafka      |    log.message.format.version = 3.0-IV1
kafka      |    log.message.timestamp.difference.max.ms = 9223372036854775807
kafka      |    log.message.timestamp.type = CreateTime
kafka      |    log.preallocate = false
kafka      |    log.retention.bytes = -1
kafka      |    log.retention.check.interval.ms = 300000
kafka      |    log.retention.hours = 168
kafka      |    log.retention.minutes = null
kafka      |    log.retention.ms = null
kafka      |    log.roll.hours = 168
kafka      |    log.roll.jitter.hours = 0
kafka      |    log.roll.jitter.ms = null
kafka      |    log.roll.ms = null
kafka      |    log.segment.bytes = 1073741824
kafka      |    log.segment.delete.delay.ms = 60000
kafka      |    max.connection.creation.rate = 2147483647
kafka      |    max.connections = 2147483647
kafka      |    max.connections.per.ip = 2147483647
kafka      |    max.connections.per.ip.overrides = 
kafka      |    max.incremental.fetch.session.cache.slots = 1000
kafka      |    message.max.bytes = 1048588
kafka      |    metadata.log.dir = null
kafka      |    metadata.log.max.record.bytes.between.snapshots = 20971520
kafka      |    metadata.log.segment.bytes = 1073741824
kafka      |    metadata.log.segment.min.bytes = 8388608
kafka      |    metadata.log.segment.ms = 604800000
kafka      |    metadata.max.retention.bytes = -1
kafka      |    metadata.max.retention.ms = 604800000
kafka      |    metric.reporters = []
kafka      |    metrics.num.samples = 2
kafka      |    metrics.recording.level = INFO
kafka      |    metrics.sample.window.ms = 30000
kafka      |    min.insync.replicas = 1
kafka      |    node.id = -1
kafka      |    num.io.threads = 8
kafka      |    num.network.threads = 3
kafka      |    num.partitions = 1
kafka      |    num.recovery.threads.per.data.dir = 1
kafka      |    num.replica.alter.log.dirs.threads = null
kafka      |    num.replica.fetchers = 1
kafka      |    offset.metadata.max.bytes = 4096
kafka      |    offsets.commit.required.acks = -1
kafka      |    offsets.commit.timeout.ms = 5000
kafka      |    offsets.load.buffer.size = 5242880
kafka      |    offsets.retention.check.interval.ms = 600000
kafka      |    offsets.retention.minutes = 10080
kafka      |    offsets.topic.compression.codec = 0
kafka      |    offsets.topic.num.partitions = 50
kafka      |    offsets.topic.replication.factor = 1
kafka      |    offsets.topic.segment.bytes = 104857600
kafka      |    password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka      |    password.encoder.iterations = 4096
kafka      |    password.encoder.key.length = 128
kafka      |    password.encoder.keyfactory.algorithm = null
kafka      |    password.encoder.old.secret = null
kafka      |    password.encoder.secret = null
kafka      |    principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka      |    process.roles = []
kafka      |    producer.purgatory.purge.interval.requests = 1000
kafka      |    queued.max.request.bytes = -1
kafka      |    queued.max.requests = 500
kafka      |    quota.window.num = 11
kafka      |    quota.window.size.seconds = 1
kafka      |    remote.log.index.file.cache.total.size.bytes = 1073741824
kafka      |    remote.log.manager.task.interval.ms = 30000
kafka      |    remote.log.manager.task.retry.backoff.max.ms = 30000
kafka      |    remote.log.manager.task.retry.backoff.ms = 500
kafka      |    remote.log.manager.task.retry.jitter = 0.2
kafka      |    remote.log.manager.thread.pool.size = 10
kafka      |    remote.log.metadata.manager.class.name = null
kafka      |    remote.log.metadata.manager.class.path = null
kafka      |    remote.log.metadata.manager.impl.prefix = null
kafka      |    remote.log.metadata.manager.listener.name = null
kafka      |    remote.log.reader.max.pending.tasks = 100
kafka      |    remote.log.reader.threads = 10
kafka      |    remote.log.storage.manager.class.name = null
kafka      |    remote.log.storage.manager.class.path = null
kafka      |    remote.log.storage.manager.impl.prefix = null
kafka      |    remote.log.storage.system.enable = false
kafka      |    replica.fetch.backoff.ms = 1000
kafka      |    replica.fetch.max.bytes = 1048576
kafka      |    replica.fetch.min.bytes = 1
kafka      |    replica.fetch.response.max.bytes = 10485760
kafka      |    replica.fetch.wait.max.ms = 500
kafka      |    replica.high.watermark.checkpoint.interval.ms = 5000
kafka      |    replica.lag.time.max.ms = 30000
kafka      |    replica.selector.class = null
kafka      |    replica.socket.receive.buffer.bytes = 65536
kafka      |    replica.socket.timeout.ms = 30000
kafka      |    replication.quota.window.num = 11
kafka      |    replication.quota.window.size.seconds = 1
kafka      |    request.timeout.ms = 30000
kafka      |    reserved.broker.max.id = 1000
kafka      |    sasl.client.callback.handler.class = null
kafka      |    sasl.enabled.mechanisms = [GSSAPI]
kafka      |    sasl.jaas.config = null
kafka      |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka      |    sasl.kerberos.min.time.before.relogin = 60000
kafka      |    sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka      |    sasl.kerberos.service.name = null
kafka      |    sasl.kerberos.ticket.renew.jitter = 0.05
kafka      |    sasl.kerberos.ticket.renew.window.factor = 0.8
kafka      |    sasl.login.callback.handler.class = null
kafka      |    sasl.login.class = null
kafka      |    sasl.login.refresh.buffer.seconds = 300
kafka      |    sasl.login.refresh.min.period.seconds = 60
kafka      |    sasl.login.refresh.window.factor = 0.8
kafka      |    sasl.login.refresh.window.jitter = 0.05
kafka      |    sasl.mechanism.controller.protocol = GSSAPI
kafka      |    sasl.mechanism.inter.broker.protocol = GSSAPI
kafka      |    sasl.server.callback.handler.class = null
kafka      |    security.inter.broker.protocol = PLAINTEXT
kafka      |    security.providers = null
kafka      |    socket.connection.setup.timeout.max.ms = 30000
kafka      |    socket.connection.setup.timeout.ms = 10000
kafka      |    socket.receive.buffer.bytes = 102400
kafka      |    socket.request.max.bytes = 104857600
kafka      |    socket.send.buffer.bytes = 102400
kafka      |    ssl.cipher.suites = []
kafka      |    ssl.client.auth = none
kafka      |    ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka      |    ssl.endpoint.identification.algorithm = https
kafka      |    ssl.engine.factory.class = null
kafka      |    ssl.key.password = null
kafka      |    ssl.keymanager.algorithm = SunX509
kafka      |    ssl.keystore.certificate.chain = null
kafka      |    ssl.keystore.key = null
kafka      |    ssl.keystore.location = null
kafka      |    ssl.keystore.password = null
kafka      |    ssl.keystore.type = JKS
kafka      |    ssl.principal.mapping.rules = DEFAULT
kafka      |    ssl.protocol = TLSv1.3
kafka      |    ssl.provider = null
kafka      |    ssl.secure.random.implementation = null
kafka      |    ssl.trustmanager.algorithm = PKIX
kafka      |    ssl.truststore.certificates = null
kafka      |    ssl.truststore.location = null
kafka      |    ssl.truststore.password = null
kafka      |    ssl.truststore.type = JKS
kafka      |    transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka      |    transaction.max.timeout.ms = 900000
kafka      |    transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka      |    transaction.state.log.load.buffer.size = 5242880
kafka      |    transaction.state.log.min.isr = 1
kafka      |    transaction.state.log.num.partitions = 50
kafka      |    transaction.state.log.replication.factor = 1
kafka      |    transaction.state.log.segment.bytes = 104857600
kafka      |    transactional.id.expiration.ms = 604800000
kafka      |    unclean.leader.election.enable = false
kafka      |    zookeeper.clientCnxnSocket = null
kafka      |    zookeeper.connect = zookeeper:2181
kafka      |    zookeeper.connection.timeout.ms = null
kafka      |    zookeeper.max.in.flight.requests = 10
kafka      |    zookeeper.session.timeout.ms = 18000
kafka      |    zookeeper.set.acl = false
kafka      |    zookeeper.ssl.cipher.suites = null
kafka      |    zookeeper.ssl.client.enable = false
kafka      |    zookeeper.ssl.crl.enable = false
kafka      |    zookeeper.ssl.enabled.protocols = null
kafka      |    zookeeper.ssl.endpoint.identification.algorithm = HTTPS
kafka      |    zookeeper.ssl.keystore.location = null
kafka      |    zookeeper.ssl.keystore.password = null
kafka      |    zookeeper.ssl.keystore.type = null
kafka      |    zookeeper.ssl.ocsp.enable = false
kafka      |    zookeeper.ssl.protocol = TLSv1.2
kafka      |    zookeeper.ssl.truststore.location = null
kafka      |    zookeeper.ssl.truststore.password = null
kafka      |    zookeeper.ssl.truststore.type = null
kafka      |    zookeeper.sync.time.ms = 2000
kafka      |  (kafka.server.KafkaConfig)
kafka      | [2025-12-08 00:47:35,716] INFO KafkaConfig values: 
kafka      |    advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
kafka      |    alter.config.policy.class.name = null
kafka      |    alter.log.dirs.replication.quota.window.num = 11
kafka      |    alter.log.dirs.replication.quota.window.size.seconds = 1
kafka      |    authorizer.class.name = 
kafka      |    auto.create.topics.enable = true
kafka      |    auto.leader.rebalance.enable = true
kafka      |    background.threads = 10
kafka      |    broker.heartbeat.interval.ms = 2000
kafka      |    broker.id = 1
kafka      |    broker.id.generation.enable = true
kafka      |    broker.rack = null
kafka      |    broker.session.timeout.ms = 9000
kafka      |    client.quota.callback.class = null
kafka      |    compression.type = producer
kafka      |    connection.failed.authentication.delay.ms = 100
kafka      |    connections.max.idle.ms = 600000
kafka      |    connections.max.reauth.ms = 0
kafka      |    control.plane.listener.name = null
kafka      |    controlled.shutdown.enable = true
kafka      |    controlled.shutdown.max.retries = 3
kafka      |    controlled.shutdown.retry.backoff.ms = 5000
kafka      |    controller.listener.names = null
kafka      |    controller.quorum.append.linger.ms = 25
kafka      |    controller.quorum.election.backoff.max.ms = 1000
kafka      |    controller.quorum.election.timeout.ms = 1000
kafka      |    controller.quorum.fetch.timeout.ms = 2000
kafka      |    controller.quorum.request.timeout.ms = 2000
kafka      |    controller.quorum.retry.backoff.ms = 20
kafka      |    controller.quorum.voters = []
kafka      |    controller.quota.window.num = 11
kafka      |    controller.quota.window.size.seconds = 1
kafka      |    controller.socket.timeout.ms = 30000
kafka      |    create.topic.policy.class.name = null
kafka      |    default.replication.factor = 1
kafka      |    delegation.token.expiry.check.interval.ms = 3600000
kafka      |    delegation.token.expiry.time.ms = 86400000
kafka      |    delegation.token.master.key = null
kafka      |    delegation.token.max.lifetime.ms = 604800000
kafka      |    delegation.token.secret.key = null
kafka      |    delete.records.purgatory.purge.interval.requests = 1
kafka      |    delete.topic.enable = true
kafka      |    fetch.max.bytes = 57671680
kafka      |    fetch.purgatory.purge.interval.requests = 1000
kafka      |    group.initial.rebalance.delay.ms = 3000
kafka      |    group.max.session.timeout.ms = 1800000
kafka      |    group.max.size = 2147483647
kafka      |    group.min.session.timeout.ms = 6000
kafka      |    initial.broker.registration.timeout.ms = 60000
kafka      |    inter.broker.listener.name = null
kafka      |    inter.broker.protocol.version = 3.0-IV1
kafka      |    kafka.metrics.polling.interval.secs = 10
kafka      |    kafka.metrics.reporters = []
kafka      |    leader.imbalance.check.interval.seconds = 300
kafka      |    leader.imbalance.per.broker.percentage = 10
kafka      |    listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
kafka      |    listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
kafka      |    log.cleaner.backoff.ms = 15000
kafka      |    log.cleaner.dedupe.buffer.size = 134217728
kafka      |    log.cleaner.delete.retention.ms = 86400000
kafka      |    log.cleaner.enable = true
kafka      |    log.cleaner.io.buffer.load.factor = 0.9
kafka      |    log.cleaner.io.buffer.size = 524288
kafka      |    log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka      |    log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka      |    log.cleaner.min.cleanable.ratio = 0.5
kafka      |    log.cleaner.min.compaction.lag.ms = 0
kafka      |    log.cleaner.threads = 1
kafka      |    log.cleanup.policy = [delete]
kafka      |    log.dir = /tmp/kafka-logs
kafka      |    log.dirs = /var/lib/kafka/data
kafka      |    log.flush.interval.messages = 9223372036854775807
kafka      |    log.flush.interval.ms = null
kafka      |    log.flush.offset.checkpoint.interval.ms = 60000
kafka      |    log.flush.scheduler.interval.ms = 9223372036854775807
kafka      |    log.flush.start.offset.checkpoint.interval.ms = 60000
kafka      |    log.index.interval.bytes = 4096
kafka      |    log.index.size.max.bytes = 10485760
kafka      |    log.message.downconversion.enable = true
kafka      |    log.message.format.version = 3.0-IV1
kafka      |    log.message.timestamp.difference.max.ms = 9223372036854775807
kafka      |    log.message.timestamp.type = CreateTime
kafka      |    log.preallocate = false
kafka      |    log.retention.bytes = -1
kafka      |    log.retention.check.interval.ms = 300000
kafka      |    log.retention.hours = 168
kafka      |    log.retention.minutes = null
kafka      |    log.retention.ms = null
kafka      |    log.roll.hours = 168
kafka      |    log.roll.jitter.hours = 0
kafka      |    log.roll.jitter.ms = null
kafka      |    log.roll.ms = null
kafka      |    log.segment.bytes = 1073741824
kafka      |    log.segment.delete.delay.ms = 60000
kafka      |    max.connection.creation.rate = 2147483647
kafka      |    max.connections = 2147483647
kafka      |    max.connections.per.ip = 2147483647
kafka      |    max.connections.per.ip.overrides = 
kafka      |    max.incremental.fetch.session.cache.slots = 1000
kafka      |    message.max.bytes = 1048588
kafka      |    metadata.log.dir = null
kafka      |    metadata.log.max.record.bytes.between.snapshots = 20971520
kafka      |    metadata.log.segment.bytes = 1073741824
kafka      |    metadata.log.segment.min.bytes = 8388608
kafka      |    metadata.log.segment.ms = 604800000
kafka      |    metadata.max.retention.bytes = -1
kafka      |    metadata.max.retention.ms = 604800000
kafka      |    metric.reporters = []
kafka      |    metrics.num.samples = 2
kafka      |    metrics.recording.level = INFO
kafka      |    metrics.sample.window.ms = 30000
kafka      |    min.insync.replicas = 1
kafka      |    node.id = -1
kafka      |    num.io.threads = 8
kafka      |    num.network.threads = 3
kafka      |    num.partitions = 1
kafka      |    num.recovery.threads.per.data.dir = 1
kafka      |    num.replica.alter.log.dirs.threads = null
kafka      |    num.replica.fetchers = 1
kafka      |    offset.metadata.max.bytes = 4096
kafka      |    offsets.commit.required.acks = -1
kafka      |    offsets.commit.timeout.ms = 5000
kafka      |    offsets.load.buffer.size = 5242880
kafka      |    offsets.retention.check.interval.ms = 600000
kafka      |    offsets.retention.minutes = 10080
kafka      |    offsets.topic.compression.codec = 0
kafka      |    offsets.topic.num.partitions = 50
kafka      |    offsets.topic.replication.factor = 1
kafka      |    offsets.topic.segment.bytes = 104857600
kafka      |    password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka      |    password.encoder.iterations = 4096
kafka      |    password.encoder.key.length = 128
kafka      |    password.encoder.keyfactory.algorithm = null
kafka      |    password.encoder.old.secret = null
kafka      |    password.encoder.secret = null
kafka      |    principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka      |    process.roles = []
kafka      |    producer.purgatory.purge.interval.requests = 1000
kafka      |    queued.max.request.bytes = -1
kafka      |    queued.max.requests = 500
kafka      |    quota.window.num = 11
kafka      |    quota.window.size.seconds = 1
kafka      |    remote.log.index.file.cache.total.size.bytes = 1073741824
kafka      |    remote.log.manager.task.interval.ms = 30000
kafka      |    remote.log.manager.task.retry.backoff.max.ms = 30000
kafka      |    remote.log.manager.task.retry.backoff.ms = 500
kafka      |    remote.log.manager.task.retry.jitter = 0.2
kafka      |    remote.log.manager.thread.pool.size = 10
kafka      |    remote.log.metadata.manager.class.name = null
kafka      |    remote.log.metadata.manager.class.path = null
kafka      |    remote.log.metadata.manager.impl.prefix = null
kafka      |    remote.log.metadata.manager.listener.name = null
kafka      |    remote.log.reader.max.pending.tasks = 100
kafka      |    remote.log.reader.threads = 10
kafka      |    remote.log.storage.manager.class.name = null
kafka      |    remote.log.storage.manager.class.path = null
kafka      |    remote.log.storage.manager.impl.prefix = null
kafka      |    remote.log.storage.system.enable = false
kafka      |    replica.fetch.backoff.ms = 1000
kafka      |    replica.fetch.max.bytes = 1048576
kafka      |    replica.fetch.min.bytes = 1
kafka      |    replica.fetch.response.max.bytes = 10485760
kafka      |    replica.fetch.wait.max.ms = 500
kafka      |    replica.high.watermark.checkpoint.interval.ms = 5000
kafka      |    replica.lag.time.max.ms = 30000
kafka      |    replica.selector.class = null
kafka      |    replica.socket.receive.buffer.bytes = 65536
kafka      |    replica.socket.timeout.ms = 30000
kafka      |    replication.quota.window.num = 11
kafka      |    replication.quota.window.size.seconds = 1
kafka      |    request.timeout.ms = 30000
kafka      |    reserved.broker.max.id = 1000
kafka      |    sasl.client.callback.handler.class = null
kafka      |    sasl.enabled.mechanisms = [GSSAPI]
kafka      |    sasl.jaas.config = null
kafka      |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka      |    sasl.kerberos.min.time.before.relogin = 60000
kafka      |    sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka      |    sasl.kerberos.service.name = null
kafka      |    sasl.kerberos.ticket.renew.jitter = 0.05
kafka      |    sasl.kerberos.ticket.renew.window.factor = 0.8
kafka      |    sasl.login.callback.handler.class = null
kafka      |    sasl.login.class = null
kafka      |    sasl.login.refresh.buffer.seconds = 300
kafka      |    sasl.login.refresh.min.period.seconds = 60
kafka      |    sasl.login.refresh.window.factor = 0.8
kafka      |    sasl.login.refresh.window.jitter = 0.05
kafka      |    sasl.mechanism.controller.protocol = GSSAPI
kafka      |    sasl.mechanism.inter.broker.protocol = GSSAPI
kafka      |    sasl.server.callback.handler.class = null
kafka      |    security.inter.broker.protocol = PLAINTEXT
kafka      |    security.providers = null
kafka      |    socket.connection.setup.timeout.max.ms = 30000
kafka      |    socket.connection.setup.timeout.ms = 10000
kafka      |    socket.receive.buffer.bytes = 102400
kafka      |    socket.request.max.bytes = 104857600
kafka      |    socket.send.buffer.bytes = 102400
kafka      |    ssl.cipher.suites = []
kafka      |    ssl.client.auth = none
kafka      |    ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka      |    ssl.endpoint.identification.algorithm = https
kafka      |    ssl.engine.factory.class = null
kafka      |    ssl.key.password = null
kafka      |    ssl.keymanager.algorithm = SunX509
kafka      |    ssl.keystore.certificate.chain = null
kafka      |    ssl.keystore.key = null
kafka      |    ssl.keystore.location = null
kafka      |    ssl.keystore.password = null
kafka      |    ssl.keystore.type = JKS
kafka      |    ssl.principal.mapping.rules = DEFAULT
kafka      |    ssl.protocol = TLSv1.3
kafka      |    ssl.provider = null
kafka      |    ssl.secure.random.implementation = null
kafka      |    ssl.trustmanager.algorithm = PKIX
kafka      |    ssl.truststore.certificates = null
kafka      |    ssl.truststore.location = null
kafka      |    ssl.truststore.password = null
kafka      |    ssl.truststore.type = JKS
kafka      |    transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka      |    transaction.max.timeout.ms = 900000
kafka      |    transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka      |    transaction.state.log.load.buffer.size = 5242880
kafka      |    transaction.state.log.min.isr = 1
kafka      |    transaction.state.log.num.partitions = 50
kafka      |    transaction.state.log.replication.factor = 1
kafka      |    transaction.state.log.segment.bytes = 104857600
kafka      |    transactional.id.expiration.ms = 604800000
kafka      |    unclean.leader.election.enable = false
kafka      |    zookeeper.clientCnxnSocket = null
kafka      |    zookeeper.connect = zookeeper:2181
kafka      |    zookeeper.connection.timeout.ms = null
kafka      |    zookeeper.max.in.flight.requests = 10
kafka      |    zookeeper.session.timeout.ms = 18000
kafka      |    zookeeper.set.acl = false
kafka      |    zookeeper.ssl.cipher.suites = null
kafka      |    zookeeper.ssl.client.enable = false
kafka      |    zookeeper.ssl.crl.enable = false
kafka      |    zookeeper.ssl.enabled.protocols = null
kafka      |    zookeeper.ssl.endpoint.identification.algorithm = HTTPS
kafka      |    zookeeper.ssl.keystore.location = null
kafka      |    zookeeper.ssl.keystore.password = null
kafka      |    zookeeper.ssl.keystore.type = null
kafka      |    zookeeper.ssl.ocsp.enable = false
kafka      |    zookeeper.ssl.protocol = TLSv1.2
kafka      |    zookeeper.ssl.truststore.location = null
kafka      |    zookeeper.ssl.truststore.password = null
kafka      |    zookeeper.ssl.truststore.type = null
kafka      |    zookeeper.sync.time.ms = 2000
kafka      |  (kafka.server.KafkaConfig)
kafka      | [2025-12-08 00:47:35,774] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka      | [2025-12-08 00:47:35,776] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka      | [2025-12-08 00:47:35,779] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka      | [2025-12-08 00:47:35,781] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka      | [2025-12-08 00:47:35,837] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
kafka      | [2025-12-08 00:47:35,840] INFO Attempting recovery for all logs in /var/lib/kafka/data since no clean shutdown file was found (kafka.log.LogManager)
kafka      | [2025-12-08 00:47:35,844] INFO Loaded 0 logs in 6ms. (kafka.log.LogManager)
kafka      | [2025-12-08 00:47:35,845] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka      | [2025-12-08 00:47:35,847] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka      | [2025-12-08 00:47:35,855] INFO Starting the log cleaner (kafka.log.LogCleaner)
kafka      | [2025-12-08 00:47:35,893] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
kafka      | [2025-12-08 00:47:36,089] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
kafka      | [2025-12-08 00:47:36,271] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka      | [2025-12-08 00:47:36,274] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
kafka      | [2025-12-08 00:47:36,301] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafka      | [2025-12-08 00:47:36,302] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka      | [2025-12-08 00:47:36,303] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.Acceptor)
kafka      | [2025-12-08 00:47:36,310] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
kafka      | [2025-12-08 00:47:36,316] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
kafka      | [2025-12-08 00:47:36,332] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka      | [2025-12-08 00:47:36,337] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka      | [2025-12-08 00:47:36,338] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka      | [2025-12-08 00:47:36,339] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka      | [2025-12-08 00:47:36,347] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka      | [2025-12-08 00:47:36,380] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
kafka      | [2025-12-08 00:47:36,399] INFO Stat of the created znode at /brokers/ids/1 is: 27,27,1765154856393,1765154856393,1,0,0,72057696505626625,270,0,27
kafka      |  (kafka.zk.KafkaZkClient)
kafka      | [2025-12-08 00:47:36,401] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 27 (kafka.zk.KafkaZkClient)
kafka      | [2025-12-08 00:47:36,438] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
kafka      | [2025-12-08 00:47:36,448] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka      | [2025-12-08 00:47:36,455] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka      | [2025-12-08 00:47:36,456] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka      | [2025-12-08 00:47:36,458] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
kafka      | [2025-12-08 00:47:36,470] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1 (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,473] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
kafka      | [2025-12-08 00:47:36,477] INFO [Controller id=1] Creating FeatureZNode at path: /feature with contents: FeatureZNode(Enabled,Features{}) (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,478] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
kafka      | [2025-12-08 00:47:36,482] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
kafka      | [2025-12-08 00:47:36,495] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafka      | [2025-12-08 00:47:36,501] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka      | [2025-12-08 00:47:36,504] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafka      | [2025-12-08 00:47:36,508] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
kafka      | [2025-12-08 00:47:36,509] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,516] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,519] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,526] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,529] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka      | [2025-12-08 00:47:36,544] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
kafka      | [2025-12-08 00:47:36,544] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 27) (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,556] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,563] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
kafka      | [2025-12-08 00:47:36,567] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
kafka      | [2025-12-08 00:47:36,577] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafka      | [2025-12-08 00:47:36,578] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
kafka      | [2025-12-08 00:47:36,580] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
kafka      | [2025-12-08 00:47:36,591] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
kafka      | [2025-12-08 00:47:36,603] INFO Kafka version: 7.0.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
kafka      | [2025-12-08 00:47:36,604] INFO Kafka commitId: b7e52413e7cb3e8b (org.apache.kafka.common.utils.AppInfoParser)
kafka      | [2025-12-08 00:47:36,604] INFO Kafka startTimeMs: 1765154856580 (org.apache.kafka.common.utils.AppInfoParser)
kafka      | [2025-12-08 00:47:36,605] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,611] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,612] INFO [Controller id=1] Current list of topics in the cluster: HashSet() (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,612] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,620] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,621] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,621] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,621] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
kafka      | [2025-12-08 00:47:36,621] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,624] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
kafka      | [2025-12-08 00:47:36,635] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
kafka      | [2025-12-08 00:47:36,661] INFO [RequestSendThread controllerId=1] Controller 1 connected to localhost:9092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
kafka      | [2025-12-08 00:47:36,661] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
kafka      | [2025-12-08 00:47:36,662] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
kafka      | [2025-12-08 00:47:36,669] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
kafka      | [2025-12-08 00:47:36,678] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap() (kafka.controller.ZkReplicaStateMachine)
kafka      | [2025-12-08 00:47:36,680] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
kafka      | [2025-12-08 00:47:36,681] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
kafka      | [2025-12-08 00:47:36,685] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap() (kafka.controller.ZkPartitionStateMachine)
kafka      | [2025-12-08 00:47:36,685] INFO [Controller id=1] Ready to serve as the new controller with epoch 1 (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,697] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,697] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,697] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,698] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,700] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,701] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker localhost:9092 (id: 1 rack: null) (state.change.logger)
kafka      | [2025-12-08 00:47:36,709] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,724] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker localhost:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
kafka      | [2025-12-08 00:47:36,727] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker localhost:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
kafka      | [2025-12-08 00:47:36,851] INFO Creating topic clicks_topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
kafka      | [2025-12-08 00:47:36,870] INFO [Controller id=1] New topics: [Set(clicks_topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(clicks_topic,Some(JzJJ4T9zRFmpvtbMVV992A),Map(clicks_topic-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,870] INFO [Controller id=1] New partition creation callback for clicks_topic-0 (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:36,871] INFO [Controller id=1 epoch=1] Changed partition clicks_topic-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka      | [2025-12-08 00:47:36,871] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka      | [2025-12-08 00:47:36,874] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition clicks_topic-0 from NonExistentReplica to NewReplica (state.change.logger)
kafka      | [2025-12-08 00:47:36,874] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka      | [2025-12-08 00:47:36,911] INFO [Controller id=1 epoch=1] Changed partition clicks_topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
kafka      | [2025-12-08 00:47:36,914] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='clicks_topic', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true) to broker 1 for partition clicks_topic-0 (state.change.logger)
kafka      | [2025-12-08 00:47:36,914] INFO [Controller id=1 epoch=1] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
kafka      | [2025-12-08 00:47:36,916] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
kafka      | [2025-12-08 00:47:36,917] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition clicks_topic-0 from NewReplica to OnlineReplica (state.change.logger)
kafka      | [2025-12-08 00:47:36,917] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka      | [2025-12-08 00:47:36,919] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 1 partitions (state.change.logger)
kafka      | [2025-12-08 00:47:36,920] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='clicks_topic', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true) correlation id 1 from controller 1 epoch 1 (state.change.logger)
kafka      | [2025-12-08 00:47:36,934] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition clicks_topic-0 (state.change.logger)
kafka      | [2025-12-08 00:47:36,934] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(clicks_topic-0) (kafka.server.ReplicaFetcherManager)
kafka      | [2025-12-08 00:47:36,934] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 1 as part of the become-leader transition for 1 partitions (state.change.logger)
kafka      | [2025-12-08 00:47:36,969] INFO [LogLoader partition=clicks_topic-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log$)
kafka      | [2025-12-08 00:47:36,983] INFO Created log for partition clicks_topic-0 in /var/lib/kafka/data/clicks_topic-0 with properties {} (kafka.log.LogManager)
kafka      | [2025-12-08 00:47:36,984] INFO [Partition clicks_topic-0 broker=1] No checkpointed highwatermark is found for partition clicks_topic-0 (kafka.cluster.Partition)
kafka      | [2025-12-08 00:47:36,984] INFO [Partition clicks_topic-0 broker=1] Log loaded for partition clicks_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka      | [2025-12-08 00:47:36,985] INFO [Broker id=1] Leader clicks_topic-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger)
kafka      | [2025-12-08 00:47:36,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition clicks_topic-0 (state.change.logger)
kafka      | [2025-12-08 00:47:36,996] INFO [Broker id=1] Finished LeaderAndIsr request in 75ms correlationId 1 from controller 1 for 1 partitions (state.change.logger)
kafka      | [2025-12-08 00:47:36,998] TRACE [Controller id=1 epoch=1] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=JzJJ4T9zRFmpvtbMVV992A, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker localhost:9092 (id: 1 rack: null) (state.change.logger)
kafka      | [2025-12-08 00:47:37,007] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='clicks_topic', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition clicks_topic-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
kafka      | [2025-12-08 00:47:37,008] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
kafka      | [2025-12-08 00:47:37,009] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker localhost:9092 (id: 1 rack: null) (state.change.logger)
kafka      | [2025-12-08 00:47:41,716] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:41,717] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:41,720] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
kafka      | [2025-12-08 00:47:41,723] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
generator  | Failed to connect to Kafka: NoBrokersAvailable. Retrying in 5 seconds...
generator  | Successfully connected to Kafka!
generator  | Sent event: {'eventid': 'evt1', 'userid': 'user13', 'url': 'categories/explore', 'timestamp': '2025-12-08T00:47:36.708426', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt2', 'userid': 'user51', 'url': 'search/explore/tags', 'timestamp': '2025-12-08T00:47:38.093274', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt3', 'userid': 'user50', 'url': 'categories/wp-content', 'timestamp': '2025-12-08T00:47:39.096665', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt4', 'userid': 'user4', 'url': 'search/wp-content/category', 'timestamp': '2025-12-08T00:47:40.099690', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt5', 'userid': 'user33', 'url': 'category/blog', 'timestamp': '2025-12-08T00:47:41.102166', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt6', 'userid': 'user37', 'url': 'search/posts', 'timestamp': '2025-12-08T00:47:42.105425', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt7', 'userid': 'user35', 'url': 'main/posts', 'timestamp': '2025-12-08T00:47:43.110140', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt8', 'userid': 'user40', 'url': 'app/category/categories', 'timestamp': '2025-12-08T00:47:44.115750', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt9', 'userid': 'user75', 'url': 'wp-content', 'timestamp': '2025-12-08T00:47:45.122410', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt10', 'userid': 'user87', 'url': 'category/wp-content/posts', 'timestamp': '2025-12-08T00:47:46.126303', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt11', 'userid': 'user31', 'url': 'wp-content/list', 'timestamp': '2025-12-08T00:47:47.128430', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt12', 'userid': 'user9', 'url': 'blog', 'timestamp': '2025-12-08T00:47:48.134449', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt13', 'userid': 'user98', 'url': 'categories/search/tag', 'timestamp': '2025-12-08T00:47:49.136112', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt14', 'userid': 'user87', 'url': 'tag/tag/tags', 'timestamp': '2025-12-08T00:47:50.140950', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt15', 'userid': 'user96', 'url': 'app/wp-content', 'timestamp': '2025-12-08T00:47:51.144464', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt16', 'userid': 'user93', 'url': 'posts', 'timestamp': '2025-12-08T00:47:52.147538', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt17', 'userid': 'user51', 'url': 'tag/tag/posts', 'timestamp': '2025-12-08T00:47:53.150562', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt18', 'userid': 'user64', 'url': 'app/explore/category', 'timestamp': '2025-12-08T00:47:54.153963', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt19', 'userid': 'user91', 'url': 'tags', 'timestamp': '2025-12-08T00:47:55.161526', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt20', 'userid': 'user49', 'url': 'tag/list', 'timestamp': '2025-12-08T00:47:56.167169', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt21', 'userid': 'user20', 'url': 'search/posts', 'timestamp': '2025-12-08T00:47:57.169079', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt22', 'userid': 'user49', 'url': 'blog/category/category', 'timestamp': '2025-12-08T00:47:58.172431', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt23', 'userid': 'user76', 'url': 'list', 'timestamp': '2025-12-08T00:47:59.176389', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt24', 'userid': 'user57', 'url': 'posts/search', 'timestamp': '2025-12-08T00:48:00.173884', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt25', 'userid': 'user20', 'url': 'search', 'timestamp': '2025-12-08T00:48:01.176846', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt26', 'userid': 'user88', 'url': 'main/main', 'timestamp': '2025-12-08T00:48:02.181837', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt27', 'userid': 'user36', 'url': 'search/wp-content/blog', 'timestamp': '2025-12-08T00:48:03.184467', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt28', 'userid': 'user8', 'url': 'tag/explore', 'timestamp': '2025-12-08T00:48:04.186442', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt29', 'userid': 'user3', 'url': 'tag', 'timestamp': '2025-12-08T00:48:05.190701', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt30', 'userid': 'user13', 'url': 'main', 'timestamp': '2025-12-08T00:48:06.194851', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt31', 'userid': 'user32', 'url': 'tag', 'timestamp': '2025-12-08T00:48:07.200933', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt32', 'userid': 'user86', 'url': 'categories', 'timestamp': '2025-12-08T00:48:08.206995', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt33', 'userid': 'user66', 'url': 'list/tags/tag', 'timestamp': '2025-12-08T00:48:09.208821', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt34', 'userid': 'user25', 'url': 'categories', 'timestamp': '2025-12-08T00:48:10.210572', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt35', 'userid': 'user90', 'url': 'tag/posts/explore', 'timestamp': '2025-12-08T00:48:11.214566', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt36', 'userid': 'user100', 'url': 'categories/wp-content/wp-content', 'timestamp': '2025-12-08T00:48:12.215996', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt37', 'userid': 'user67', 'url': 'app/categories/category', 'timestamp': '2025-12-08T00:48:13.217411', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt38', 'userid': 'user97', 'url': 'app', 'timestamp': '2025-12-08T00:48:14.223011', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt39', 'userid': 'user64', 'url': 'tags', 'timestamp': '2025-12-08T00:48:15.227448', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt40', 'userid': 'user48', 'url': 'category/list', 'timestamp': '2025-12-08T00:48:16.232574', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt41', 'userid': 'user20', 'url': 'search/categories/wp-content', 'timestamp': '2025-12-08T00:48:17.239018', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt42', 'userid': 'user33', 'url': 'tag', 'timestamp': '2025-12-08T00:48:18.243656', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt43', 'userid': 'user30', 'url': 'category', 'timestamp': '2025-12-08T00:48:19.246091', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt44', 'userid': 'user6', 'url': 'posts/app', 'timestamp': '2025-12-08T00:48:20.250753', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt45', 'userid': 'user12', 'url': 'search/categories', 'timestamp': '2025-12-08T00:48:21.256988', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt46', 'userid': 'user53', 'url': 'app', 'timestamp': '2025-12-08T00:48:22.258425', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt47', 'userid': 'user50', 'url': 'tag/main', 'timestamp': '2025-12-08T00:48:23.264994', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt48', 'userid': 'user3', 'url': 'explore', 'timestamp': '2025-12-08T00:48:24.265788', 'action': 'view_item'}
generator  | Sent event: {'eventid': 'evt49', 'userid': 'user14', 'url': 'main/wp-content', 'timestamp': '2025-12-08T00:48:25.267670', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt50', 'userid': 'user1', 'url': 'category/posts', 'timestamp': '2025-12-08T00:48:26.271103', 'action': 'add_to_cart'}
generator  | Sent event: {'eventid': 'evt51', 'userid': 'user62', 'url': 'list/wp-content', 'timestamp': '2025-12-08T00:48:27.277623', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt52', 'userid': 'user37', 'url': 'main', 'timestamp': '2025-12-08T00:48:28.282198', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt53', 'userid': 'user92', 'url': 'categories/posts', 'timestamp': '2025-12-08T00:48:29.287004', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt54', 'userid': 'user33', 'url': 'explore/categories/category', 'timestamp': '2025-12-08T00:48:30.297299', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt55', 'userid': 'user6', 'url': 'explore/categories', 'timestamp': '2025-12-08T00:48:31.297912', 'action': 'checkout'}
generator  | Sent event: {'eventid': 'evt56', 'userid': 'user69', 'url': 'search', 'timestamp': '2025-12-08T00:48:32.299607', 'action': 'checkout'}
Gracefully stopping... (press Ctrl+C again to force)
[+] Stopping 4/4
 ✔ Container generator  Stopped                                                                                                                                                6.9s 
 ✔ Container minio      Stopped                                                                                                                                                0.2s 
 ✔ Container kafka      Stopped                                                                                                                                                0.1s 
 ✔ Container zookeeper  Stopped     